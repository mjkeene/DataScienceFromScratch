{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef7e341",
   "metadata": {},
   "source": [
    "<h3>Chapter 5: Statistics</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af61f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central Tendencies\n",
    "\n",
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "def median(v):\n",
    "    n = len(v)\n",
    "    sorted_v = sorted(v)\n",
    "    midpoint = n // 2\n",
    "    \n",
    "    if n % 2 == 1:\n",
    "        return sorted_v[midpoint]\n",
    "    else:\n",
    "        low = midpoint - 1\n",
    "        high = midpoint\n",
    "        return (sorted_v[low] + sorted_v[high]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "768e3d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile(x, p):\n",
    "    \"\"\"returns the pth-percentile value in x\"\"\"\n",
    "    p_index = int(p * len(x))\n",
    "    return sorted(x)[p_index]\n",
    "\n",
    "def mode(x):\n",
    "    \"\"\"returns a list, might be more than one mode\"\"\"\n",
    "    counts = Counter(x)\n",
    "    max_count = max(counts.values())\n",
    "    return [x_i for x_i, count in counts.items() if count == max_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2320bcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dispersion\n",
    "def data_range(x):\n",
    "    return max(x) - min(x)\n",
    "\n",
    "data_range([1,2,5,99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2453273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_mean(x):\n",
    "    \"\"\"translate x by subtracting its mean (so the result has mean 0)\"\"\"\n",
    "    x_bar = mean(x)\n",
    "    return [x_i - x_bar for x_i in x]\n",
    "de_mean([1,2,3,4, 99])\n",
    "\n",
    "def dot(v, w):\n",
    "    \"\"\"The dot product of two vectors is the sum of their componentwise products\n",
    "    v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "def sum_of_squares(v):\n",
    "    \"\"\"v_1 * v_1 + ... + v_n * v_n\"\"\"\n",
    "    return dot(v, v)\n",
    "\n",
    "def variance(x):\n",
    "    \"\"\"assumes x has at least two elements\"\"\"\n",
    "    n = len(x)\n",
    "    deviations = de_mean(x)\n",
    "    return sum_of_squares(deviations) / (n-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef70a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def standard_deviation(x):\n",
    "    return math.sqrt(variance(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a068902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.50687236533259"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_deviation([1,2,3,99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b544ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is more robust to outliers than standard deviation and variance\n",
    "def interquartile_range(x):\n",
    "    return quantile(x, 0.75) - quantile(x, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b587ecec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568.15"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covariance is the paired analogue of variance\n",
    "# It measures how two variables vary in tandem from their means\n",
    "def covariance(x, y):\n",
    "    n = len(x)\n",
    "    return dot(de_mean(x), de_mean(y)) / (n-1)\n",
    "\n",
    "num_friends = [20, 90, 200, 3, 15]\n",
    "num_daily_minutes = [10, 20, 50, 2, 7]\n",
    "\n",
    "covariance(num_friends, num_daily_minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d5983",
   "metadata": {},
   "source": [
    "Recall that a dot sums up the products of corresponding pairs of elements. When corresponding elements of x and y are either both above their means or below their means, a positive number enters the sum. When one is above its mean and the other below, a negative number enters the sum. A \"large\" positive covariance means that x tends to be large when y is large and small when y is small. A \"large\" negative covariance means the opposite -- that x tends to be small when y is large and vice versa. A covariance close to zero means that no such relationship exists. \n",
    "\n",
    "However, the number can be hard to interpret for the following reasons:\n",
    "1. Its units are the product of the inputs' units (e.g., friend-minutes-per-day) which can be hard to make sense of.\n",
    "2. If each user had twice as many friends (but the same number of minutes), the covariance would be twice as large. But in a sense the variables would be just as interrelated. It's hard to say what counts as a \"large\" covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa1322a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920750771995687"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always lies between -1 and 1\n",
    "\n",
    "def correlation(x, y):\n",
    "    stdev_x = standard_deviation(x)\n",
    "    stdev_y = standard_deviation(y)\n",
    "    if stdev_x > 0 and stdev_y > 0:\n",
    "        return covariance(x, y) / stdev_x / stdev_y\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "correlation(num_friends, num_daily_minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a56cb6a",
   "metadata": {},
   "source": [
    "<h3> Simpson's Paradox</h3>\n",
    "\n",
    "Correlations can be misleading when <i>confounding</i> variables are ignored. For example, imagine that you can identify all members as either east coast data scientists or west coast data scientists to see which are friendlier. Just looking at the coast, you may find that the west coast data scientists have more friends on average. However, after accounting for their type of degree (PhD vs. non-PhD), you find that actually east coast people have more friends on average when splitting the data based on degree type. Bucketing the data as east coast/west coast disguised the fact that the east coast data scientists skew much more heavily toward PhD types. \n",
    "\n",
    "The key issue is that correlation is measuring the relationship between your two variables <i>all else being equal</i>. If your data classes are assigned at random, as they might be in a well-designed experiment, \"all else being equal\" might not be a terrible assumption. But when there is a deeper pattern to class assignments, \"all else being equal\" can be a terrible assumption.\n",
    "\n",
    "The only way to avoid this is by <i>knowing your data</i> and doing what you can to make sure you've checked for possible confounding factors. Obviously this is not always possible -- if you didn't have the educational attainment of the data scientists, you may simply conclude that there was something inherently more sociable about the West Coast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "970d665e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A correlation of zero indicates that there is no linear relationship\n",
    "# between the two variables. However, there are other sorts of relationships\n",
    "\n",
    "\n",
    "x = [-2,-1,0,1,2]\n",
    "y = [2, 1,0,1,2]\n",
    "correlation(x, y)\n",
    "\n",
    "# Here, each element of y equals the absolute value of the correspoinding\n",
    "# element of x. What they do not have is a relationship in which knowing\n",
    "# how x_i compares to mean(x) gives us information about how Y_i\n",
    "# compares to mean(y). That's what correlation looks for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76ad3365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additionally, correlation tells you nothing about how large the\n",
    "# relationship actually is. These variables are perfectly correlated,\n",
    "# but depending on what you're measuring, it's quite possible that\n",
    "# the relationship isn't all that interesting\n",
    "x = [-2,-1,0,1,2]\n",
    "y = [99.98, 99.99, 100, 100.01, 100.02]\n",
    "correlation(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c93d3",
   "metadata": {},
   "source": [
    "<h3>Correlation and Causation</h3>\n",
    "\n",
    "If x and y are strongly correlated, that might mean x causes y, that y causes x, that each causes the other, that some third factor causes both, or it might mean nothing.\n",
    "\n",
    "Consider the relationship between num_friends and daily_minutes. It's possible that having more friends on the site <i>causes</i> DataSciencester users to spend more time on the site. This might be the case if each friend posts a certain amount of content each day, which means that the more friends you have, the more time it takes to stay current with their updates. \n",
    "\n",
    "However, it's also possible that the more time you spend arguing in the forums, the more you encounter and befriend like-minded people. That is, spending more time on the site <i>causes</i> users to have more friends.\n",
    "\n",
    "A third possibility is that the users who are most passionate about DS spend more time on the site and more actively collect data science friends. \n",
    "\n",
    "One way to feel more confident about causality is by conducting randomized trials. If you can randomly split your users into two groups with similar demographics and give one of the groups a slightly different experience, then you can often feel pretty good that the different experiences are causing the different outcomes. \n",
    "\n",
    "For example, you could randomly choose a subset of your users and show them content from only a fraction of their friends. If this subset subsequently spent less time on the site, this would give you some confidence that having more friends <i>causes</i> more time to be spent on the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866481a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
